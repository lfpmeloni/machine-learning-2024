{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Aufgabe mit Iris Dataset\n",
    "\n",
    "a) Load the Iris dataset using load_iris() and split into training/testing sets.\n",
    "Scale the data using StandardScaler.\n",
    "Train a KNeighborsClassifier, experiment with n_neighbors and p, and calculate the test score.\n",
    "\n",
    "b) Train a GaussianNB (Naive Bayes) and LogisticRegression on the scaled training data and compute their test scores.\n",
    "\n",
    "c) Use cross_val_score for 5-fold cross-validation on each model to compute mean and standard deviation of their scores, comparing their performance across folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load Iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Load and split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = iris.data, iris.target  # Load features and target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data using StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Test Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# a) K-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3, p=2)  # Experiment with n_neighbors and p\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "knn_score = knn.score(X_test_scaled, y_test)\n",
    "print(f\"KNN Test Score: {knn_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Test Score: 0.9778\n"
     ]
    }
   ],
   "source": [
    "# b) Naive Bayes and Logistic Regression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_scaled, y_train)\n",
    "gnb_score = gnb.score(X_test_scaled, y_test)\n",
    "print(f\"Naive Bayes Test Score: {gnb_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# b) Naive Bayes and Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "log_reg_score = log_reg.score(X_test_scaled, y_test)\n",
    "print(f\"Logistic Regression Test Score: {log_reg_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "knn_cv_scores = cross_val_score(knn, X_train_scaled, y_train, cv=5)\n",
    "gnb_cv_scores = cross_val_score(gnb, X_train_scaled, y_train, cv=5)\n",
    "log_reg_cv_scores = cross_val_score(log_reg, X_train_scaled, y_train, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Results:\n",
      "KNN: Mean=0.9429, Std=0.0467\n",
      "Naive Bayes: Mean=0.9333, Std=0.0381\n",
      "Logistic Regression: Mean=0.9429, Std=0.0356\n"
     ]
    }
   ],
   "source": [
    "# Compare cross-validation results\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(f\"KNN: Mean={knn_cv_scores.mean():.4f}, Std={knn_cv_scores.std():.4f}\")\n",
    "print(f\"Naive Bayes: Mean={gnb_cv_scores.mean():.4f}, Std={gnb_cv_scores.std():.4f}\")\n",
    "print(f\"Logistic Regression: Mean={log_reg_cv_scores.mean():.4f}, Std={log_reg_cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean score represents the average accuracy of the model across the 5 cross-validation folds. Higher mean scores indicate better average performance. All three models perform well overall, with accuracies above 93%.\n",
    "\n",
    "The standard deviation measures how much the scores vary across different folds. Lower standard deviation means more consistent performance across folds, suggesting the model generalizes well. Best Average Accuracy: KNN and Logistic Regression tie for the highest mean accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
